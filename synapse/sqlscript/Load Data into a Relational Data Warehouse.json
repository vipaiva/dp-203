{
	"name": "Load Data into a Relational Data Warehouse",
	"properties": {
		"folder": {
			"name": "dp-203/04-Dedicated SQL/09-Lab-Load data into a relational data warehouse"
		},
		"content": {
			"query": "/*\n1. Load data from a data lake by using the COPY statement\n---------------------------------------------------------\n\nConfirm that there are 0 rows currently in the StageProduct table.\n*/\n\nSELECT COUNT(1) \nFROM dbo.StageProduct\n\n/*\nRun the following command. 11 rows should have been loaded into the StageProduct table.\n*/\n\nCOPY INTO dbo.StageProduct\n    (ProductID, ProductName, ProductCategory, Color, Size, ListPrice, Discontinued)\nFROM 'https://datalakevipaiva.blob.core.windows.net/files/labs-dp-203/09/data/Product.csv'\nWITH\n(\n    FILE_TYPE = 'CSV',\n    MAXERRORS = 0,\n    IDENTITY_INSERT = 'OFF',\n    FIRSTROW = 2 --Skip header row\n);\n\n/*\nNow let's use the same technique to load another table, this time logging any errors that might occur.\n\nNotice the messages tab:\nQuery completed. Rows were rejected while reading from external source(s). 1 row rejected from table [StageCustomer] \nin plan step 4 of query execution: Bulk load data conversion error (type mismatch or invalid character for the \nspecified codepage) for row starting at byte offset 2261, column 1 (GeographyKey) in data file /labs/09/data/Customer.csv.\n*/\n\nCOPY INTO dbo.StageCustomer\n    (GeographyKey, CustomerAlternateKey, Title, FirstName, MiddleName, LastName, NameStyle, BirthDate, \n    MaritalStatus, Suffix, Gender, EmailAddress, YearlyIncome, TotalChildren, NumberChildrenAtHome, EnglishEducation, \n    SpanishEducation, FrenchEducation, EnglishOccupation, SpanishOccupation, FrenchOccupation, HouseOwnerFlag, \n    NumberCarsOwned, AddressLine1, AddressLine2, Phone, DateFirstPurchase, CommuteDistance)\nFROM 'https://datalakevipaiva.blob.core.windows.net/files/labs-dp-203/09/data/Customer.csv'\nWITH\n(\nFILE_TYPE = 'CSV'\n,MAXERRORS = 5\n,FIRSTROW = 2 -- skip header row\n,ERRORFILE = 'https://datalakevipaiva.blob.core.windows.net/files/labs-dp-203/09/errors/'\n);\n\n/*\nThe source file contains a row with invalid data, so one row is rejected. The code above specifies a maximum of 5 errors, so a single \nerror should not have prevented the valid rows from being loaded. You can view the rows that have been loaded by running the following query.\n*/\n\nSELECT *\nFROM dbo.StageCustomer\n\n/*\nOn the files tab, view the folder of your data lake (files/labs/09) and verify that a new folder named _rejectedrows has been created \n(if you don't see this folder, in the More menu, select Refresh to refresh the view).\n\nOpen the _rejectedrows folder and the date and time specific subfolder it contains, and note that files with names similar to QID123_1_2.Error.Txt \nand QID123_1_2.Row.Txt have been created. You can right-click each of these files and select Preview to see details of the error and the row that was rejected.\n\n- \"Bulk load data conversion error (type mismatch or invalid character for the specified codepage) for row starting at byte offset 2261, column 1 (GeographyKey) in data file /labs/09/data/Customer.csv.\"\n- \"US,AW99,,Billy,L,Jones,FALSE,Dec 12th 2001\"\n\n(notice the value \"US\")\n\nThe use of staging tables enables you to validate or transform data before moving or using it to append to or upsert into any existing dimension tables. \nThe COPY statement provides a simple but high-performance technique that you can use to easily load data from files in a data lake into staging tables, \nand as you've seen, identify and redirect invalid rows.\n*/\n\n/*\n2. Use a CREATE TABLE AS (CTAS) statement\n-----------------------------------------\n\nThe following SQL creates a new table named DimProduct from the staged product data that uses ProductAltKey as its\nhash distribution key and has a clustered columnstore index.\n*/\n\nIF EXISTS (SELECT 1 FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'dbo' AND TABLE_NAME = 'DimProductLab9') DROP TABLE [dbo].[DimProductLab9];\n\nCREATE TABLE dbo.DimProductLab9\nWITH\n(\n    DISTRIBUTION = HASH(ProductAltKey),\n    CLUSTERED COLUMNSTORE INDEX\n)\nAS\nSELECT ROW_NUMBER() OVER(ORDER BY ProductID) AS ProductKey,\n    ProductID AS ProductAltKey,\n    ProductName,\n    ProductCategory,\n    Color,\n    Size,\n    ListPrice,\n    Discontinued\nFROM dbo.StageProduct;\n\n/*\nUse the following query to view the contents of the new DimProduct table:\n\nThe CREATE TABLE AS SELECT (CTAS) expression has various uses, which include:\n\n- Redistributing the hash key of a table to align with other tables for better query performance.\n- Assigning a surrogate key to a staging table based upon existing values after performing a delta analysis.\n- Creating aggregate tables quickly for report purposes.\n\n*/\n\nSELECT ProductKey,\n    ProductAltKey,\n    ProductName,\n    ProductCategory,\n    Color,\n    Size,\n    ListPrice,\n    Discontinued\nFROM dbo.DimProductLab9;\n\n/*\n3. Combine INSERT and UPDATE statements to load a slowly changing dimension table\n---------------------------------------------------------------------------------\nThe DimCustomer table supports type 1 and type 2 slowly changing dimensions (SCDs), where type 1 changes result in \nan in-place update to an existing row, and type 2 changes result in a new row to indicate the latest version of a \nparticular dimension entity instance. Loading this table requires a combination of INSERT statements (to load new customers) \nand UPDATE statements (to apply type 1 or type 2 changes).\n*/\n\n\nINSERT INTO dbo.DimCustomer ([GeographyKey],[CustomerAlternateKey],[Title],[FirstName],[MiddleName],[LastName],[NameStyle],[BirthDate],[MaritalStatus],\n[Suffix],[Gender],[EmailAddress],[YearlyIncome],[TotalChildren],[NumberChildrenAtHome],[EnglishEducation],[SpanishEducation],[FrenchEducation],\n[EnglishOccupation],[SpanishOccupation],[FrenchOccupation],[HouseOwnerFlag],[NumberCarsOwned],[AddressLine1],[AddressLine2],[Phone],\n[DateFirstPurchase],[CommuteDistance])\nSELECT *\nFROM dbo.StageCustomer AS stg\nWHERE NOT EXISTS\n    (SELECT * FROM dbo.DimCustomer AS dim\n    WHERE dim.CustomerAlternateKey = stg.CustomerAlternateKey);\n\n-- Type 1 updates (change name, email, or phone in place)\nUPDATE dbo.DimCustomer\nSET LastName = stg.LastName,\n    EmailAddress = stg.EmailAddress,\n    Phone = stg.Phone\nFROM DimCustomer dim inner join StageCustomer stg\nON dim.CustomerAlternateKey = stg.CustomerAlternateKey\nWHERE dim.LastName <> stg.LastName OR dim.EmailAddress <> stg.EmailAddress OR dim.Phone <> stg.Phone\n\n-- Type 2 updates (address changes triggers new entry)\nINSERT INTO dbo.DimCustomer\nSELECT stg.GeographyKey,stg.CustomerAlternateKey,stg.Title,stg.FirstName,stg.MiddleName,stg.LastName,stg.NameStyle,stg.BirthDate,stg.MaritalStatus,\nstg.Suffix,stg.Gender,stg.EmailAddress,stg.YearlyIncome,stg.TotalChildren,stg.NumberChildrenAtHome,stg.EnglishEducation,stg.SpanishEducation,stg.FrenchEducation,\nstg.EnglishOccupation,stg.SpanishOccupation,stg.FrenchOccupation,stg.HouseOwnerFlag,stg.NumberCarsOwned,stg.AddressLine1,stg.AddressLine2,stg.Phone,\nstg.DateFirstPurchase,stg.CommuteDistance\nFROM dbo.StageCustomer AS stg\nJOIN dbo.DimCustomer AS dim\nON stg.CustomerAlternateKey = dim.CustomerAlternateKey\nAND stg.AddressLine1 <> dim.AddressLine1;\n\n/*\n4. Perform post-load optimization\n---------------------------------\n\nAfter loading new data into the data warehouse, it's recommended to rebuild the table indexes and update statistics on commonly queried columns.\n*/\n\nALTER INDEX ALL ON dbo.DimProductLab9 REBUILD;\n\nCREATE STATISTICS customergeo_stats ON dbo.DimCustomer (GeographyKey);\n\n/*\nGet ready for the next demo (10-pipelines)\n*/\n\nIF EXISTS (SELECT 1 FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'dbo' AND TABLE_NAME = 'DimProductLab10') DROP TABLE [dbo].[DimProductLab10];\n\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\nCREATE TABLE [dbo].[DimProductLab10](\n    [ProductKey] [int] IDENTITY NOT NULL,\n    [ProductAltKey] [nvarchar](30) NULL,\n    [ProductName] [nvarchar](50) NULL,\n    [Color] [nvarchar](30) NULL,\n    [Size] [nvarchar](50) NULL,\n    [ListPrice] [money] NULL,\n    [Discontinued] [bit] NULL)\nWITH\n(\n\tDISTRIBUTION = HASH(ProductAltKey),\n\tCLUSTERED COLUMNSTORE INDEX\n);\nGO\n\nINSERT DimProductLab10\nVALUES('AR-5381','Adjustable Race','Red',NULL,1.99,0);\nGO\n\nINSERT DimProductLab10 VALUES('AR-5381','Adjustable Race','Red',NULL,1.99,0);\nGO\n\nDROP TABLE [dbo].[DimProductLab9];\n\n\n\n\n-- Create a temporary table for the dates we need\nCREATE TABLE #TmpStageDate (DateVal DATE NOT NULL)\n\n-- Populate the temp table with a range of dates\nDECLARE @StartDate DATE\nDECLARE @EndDate DATE\nSET @StartDate = '2019-01-01'\nSET @EndDate = '2022-12-31' \nDECLARE @LoopDate DATE\nSET @LoopDate = @StartDate\nWHILE @LoopDate <= @EndDate\nBEGIN\n    INSERT INTO #TmpStageDate VALUES\n    (\n        @LoopDate\n    ) \n    SET @LoopDate = DATEADD(dd, 1, @LoopDate)\nEND\n\n-- Insert the dates into the dimension table\nINSERT INTO dbo.DimDate \nSELECT  \n    CAST(CONVERT(VARCHAR(8), DateVal, 112) AS int) AS DateKey, -- date key\n    DateVal AS DateAltKey, -- date alt key\n    Day(DateVal) AS DayNumberOfMonth, -- day number of month\n    MONTH(DateVal) AS MonthNumberOfYear, -- month number of year\n    YEAR(DateVal) AS YearNumber -- year number\n    -- , other derived temporal fields as required\nFROM  #TmpStageDate\n\n-- Drop the temporary table\nDROP TABLE #TmpStageDate\n\ndrop table dim\n\n\n\n\n\n\nINSERT INTO dbo.FactSales\nSELECT  (SELECT MAX(DateKey)\n         FROM dbo.DimDate\n         WHERE FullDateAlternateKey = stg.OrderDate) AS OrderDateKey,\n        (SELECT MAX(CustomerKey)\n         FROM dbo.DimCustomer\n         WHERE CustomerAlternateKey = stg.CustNo) AS CustomerKey,\n        (SELECT MAX(ProductKey)\n         FROM dbo.DimProduct\n         WHERE ProductAlternateKey = stg.ProductID) AS ProductKey,\n        '',\n        OrderNumber,\n        OrderLineItem,\n        OrderQuantity,\n        UnitPrice,\n        Discount,\n        Tax,\n        SalesAmount\nFROM dbo.StageSales AS stg\n\n\n",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "sqldwh",
				"poolName": "sqldwh"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}