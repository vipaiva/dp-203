{
	"name": "Covid Analysis ES",
	"properties": {
		"folder": {
			"name": "dp-203/02-Serverless SQL/02-Demo-Query files using a serverless SQL pool"
		},
		"content": {
			"query": "\nselect top 10  *\nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.csv',\n                format='csv', parser_version='2.0') as a\n                \n-- Use HEADER_ROW because this file has header                \nselect top 10  *\nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.csv',\n                format='csv', parser_version='2.0', FIRSTROW = 2) as a\n\nselect top 10\n        cases = json_value(doc, '$.cases'),\n        *\nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.jsonl',\n                format='csv', fieldterminator ='0x0b', fieldquote = '0x0b') with (doc nvarchar(max)) as a\n\nselect top 10  *\nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',\n                format='parquet') as a\n\n-- ## Explore your data \n-- As a first step we need to explore data in the file place in Azure storage using `OPENROWSET` function:\n\nselect top 10  *  \nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',  \n                format='parquet') as a\n\n\n-- Here we can see that some of the columns interesting for analysis are `DATE_REP` and `CASES`. I would like to analyze number of cases reported in Spain, so I would need to filter the results using `GEO_ID` column. \n-- We are not sure what is `geo_id` value for Spain, so we will find all distinct countries and `geo_id` values where country is something like Spain:\n\nselect distinct countries_and_territories, geo_id  \nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',  \n                format='parquet') as a  \nwhere countries_and_territories like '%Spa%'\n\n\n-- Since we see that `GEO_ID` for Spain is `ES`, we can find dayly number of cases in Spain:\nselect DATE_REP, CASES  \nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',  \n                format='parquet') as a  \nwhere geo_id = 'ES'  \norder by date_rep\n\n\n-- We can show this in the chart to see trend analysis of reported COVID cases in Spain. By looking at this chart, we can see that the peek is somewhere between 15th and 20th April and the peak in the second wave is second half of July. \n-- The points on time series charts are shown per daily basis. This might lead to daily variation, so you might want to show the graph with average values calculated in the window with +/- 1-2 days. T-SQL enables you to easily calculate average values if you specify time window: \n-- ``` \n-- AVG(CASES) OVER(order by date_rep ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING  ) \n-- ``` \n-- We need to specify how to locally order data and number of preceding/following rows that AVG function should use to calculate the average value within the window. The time series query that uses average values is shown on the following code:\n\nselect  DATE_REP,  \n        CASES_AVG = AVG(CASES) OVER(ORDER BY date_rep ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING  )  \nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet', format='parquet') as a  \nwhere geo_id = 'ES'  \norder by date_rep\n\n\n-- We can also show cumulative values to see increase of the number of cases over time (this is known as running total):\n\nselect DATE_REP,  \n        CUMULATIVE = SUM(CASES) OVER (ORDER BY date_rep)  \nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',  \n                format='parquet') as a  \nwhere geo_id = 'ES'  \norder by date_rep\n\n\n-- If we switch to chart we can see cumulative number of cases that are reported since the first COVID case. \n-- SQL language enables us to easily lookup number of reported cases couple of days after or before using LAG and LEAD functions. the following query will return number of cases reported 7 days ago:\n\nselect  TOP 10 date_rep,  \n        cases,  \n        prev = LAG(CASES, 7) OVER(partition by geo_id order by date_rep )  \nfrom openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',  \n                        format='parquet') as a  \nwhere geo_id = 'ES'\norder by date_rep desc;\n\n\n-- You can notice in the result that prev column lag 7 days to the current column. Now we can easily compare the difference between the current number of reported cases of the number of reported cases reported or percent of increase: \n-- ``` \n-- WoW% = (cases - prev) / prev \n--      = cases/prev - 1 \n-- ``` \n-- Instead of simple comparison of current and previous value, we can make this more reliable and first calculate the average values in the 7-day windows and then calculate increase using these values:\n\nwith ecdc as (  \n    select  \n        date_rep,  \n        cases = AVG(CASES) OVER(partition by geo_id order by date_rep ROWS BETWEEN 7 PRECEDING AND CURRENT ROW  ),  \n        prev = AVG(CASES) OVER(partition by geo_id order by date_rep ROWS BETWEEN 14 PRECEDING AND 7 PRECEDING  )  \n    from  \n        openrowset(bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',  \n                    format='parquet') as a  \n    where  \n        geo_id = 'ES'\n)  \nselect date_rep, cases, prev, [WoW%] = 100*(1.0*cases/prev - 1)  \nfrom ecdc  \nwhere prev > 10  \norder by date_rep asc;\n\n",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "master",
				"poolName": "Built-in"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}